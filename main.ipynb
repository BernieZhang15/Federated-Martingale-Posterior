{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "import torch\n",
    "import warnings\n",
    "import numpy as np\n",
    "from modules import ISAB, PMA\n",
    "from netcal.metrics import ENCE\n",
    "warnings.filterwarnings(\"ignore\", message=\".*Can't initialize NVML.*\",category=UserWarning)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-21T13:06:21.388354Z",
     "start_time": "2025-12-21T13:06:21.312015Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data = np.load(\"data/central_dataset.npz\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "X_c = torch.from_numpy(data[\"X_train\"]).float().to(device)\n",
    "y_c = torch.from_numpy(data[\"y_train\"]).float().unsqueeze(-1).to(device)\n",
    "context_c = torch.cat((X_c, y_c), dim=1)\n",
    "\n",
    "X_test = torch.from_numpy(data[\"X_test\"]).float().to(device)\n",
    "y_test = torch.from_numpy(data[\"y_test\"]).float().unsqueeze(-1).to(device)\n",
    "\n",
    "d_ctx = context_c.size(1)\n",
    "d_x = X_c.size(1)\n",
    "d_y = y_c.size(1)\n",
    "K = 32\n",
    "\n",
    "sigma2_true = 0.1\n",
    "sigma_true = np.sqrt(sigma2_true)\n",
    "\n",
    "isab = ISAB(d_ctx, d_ctx, 5, 128, ln=True).to(device)\n",
    "isab_dict = torch.load(\"checkpoint/isab_model.pt\", map_location=device)\n",
    "isab.load_state_dict(isab_dict)\n",
    "isab.eval()\n",
    "\n",
    "W_cmps = []\n",
    "\n",
    "for i in range(K):\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        predictive_c = isab(context_c)\n",
    "    \n",
    "    predictive_cx, predictive_cy = predictive_c[:, :d_x], predictive_c[:, d_x:]\n",
    "    \n",
    "    # X_cmp = torch.cat((X_c, predictive_cx), dim=0)\n",
    "    # y_cmp = torch.cat((y_c, predictive_cy), dim=0)\n",
    "    \n",
    "    X_cmp = predictive_cx\n",
    "    y_cmp = predictive_cy\n",
    "    \n",
    "    XTX_cmp = X_cmp.T @ X_cmp \n",
    "    XTy_cmp = X_cmp.T @ y_cmp\n",
    "    w_cmp = torch.linalg.solve(XTX_cmp, XTy_cmp)\n",
    "    \n",
    "    W_cmps.append(w_cmp)\n",
    "\n",
    "W_cmps_stacked = torch.stack(W_cmps, dim=0).squeeze(-1) # (K, d_x)\n",
    "\n",
    "XTX_cnbl = X_c.T @ X_c\n",
    "XTy_cnbl= X_c.T @ y_c\n",
    "w_cnbl = torch.linalg.solve(XTX_cnbl, XTy_cnbl)\n",
    "\n",
    "with torch.no_grad():\n",
    "    y_test_cnbl = X_test @ w_cnbl\n",
    "    mse_test_cnbl = torch.mean((y_test_cnbl - y_test) ** 2).item()\n",
    "    print(f\"Predictive MSE (centralized OLS, real data only): {mse_test_cnbl}\")\n",
    "    \n",
    "with torch.no_grad():  \n",
    "    y_test_cmps = torch.einsum('bd, nd->bn', W_cmps_stacked, X_test) # (K, N)\n",
    "    y_test_cmp_mean = y_test_cmps.mean(dim=0).view(-1)\n",
    "    y_test_cmp_var = y_test_cmps.var(dim=0, unbiased=True).view(-1)\n",
    "    \n",
    "    mse_test_cmp_mean = torch.mean((y_test_cmp_mean.view(-1, 1) - y_test) ** 2).item()\n",
    "    print(f\"Predictive MSE using mean of K MP samples: {mse_test_cmp_mean}\")\n",
    "\n",
    "y_test_np = y_test.view(-1).cpu().numpy()\n",
    "y_test_mean_cnbl_np = y_test_cnbl.view(-1).cpu().numpy()\n",
    "y_test_std_cnbl_np =  sigma_true * np.ones_like(y_test_mean_cnbl_np)\n",
    "\n",
    "y_test_mean_cmp_np = y_test_cmp_mean.cpu().numpy()\n",
    "y_test_cmp_var += sigma2_true\n",
    "y_test_std_cmp_np = np.sqrt(y_test_cmp_var.cpu().numpy())\n",
    "\n",
    "def ence_with_fallback(y_mean, y_std, y_true, bins=10, eps=1e-8):\n",
    "    y_true = np.asarray(y_true).reshape(-1)\n",
    "    y_mean = np.asarray(y_mean).reshape(-1)\n",
    "    y_std  = np.asarray(y_std).reshape(-1)\n",
    "\n",
    "    if np.allclose(y_std, y_std[0], rtol=1e-6, atol=1e-8):\n",
    "        mse = np.mean((y_true - y_mean) ** 2)\n",
    "        u_hat = np.mean(y_std ** 2) \n",
    "        ence = np.abs(mse - u_hat) / (max(mse, u_hat) + eps)\n",
    "        return float(ence)\n",
    "\n",
    "    ence_metric = ENCE(bins=bins)\n",
    "    return float(ence_metric.measure((y_mean, y_std), y_true))\n",
    "\n",
    "ence_cnbl = ence_with_fallback(y_test_mean_cnbl_np, y_test_std_cnbl_np, y_test_np)\n",
    "ence_cmp = ence_with_fallback(y_test_mean_cmp_np, y_test_std_cmp_np, y_test_np)\n",
    "\n",
    "print(f\"ENCE (Non Bayesian OLS, real data only): {ence_cnbl}\")\n",
    "print(f\"ENCE (CMP): {ence_cmp}\")\n",
    "\n",
    "err2 = (y_test_cmp_mean.view(-1,1) - y_test).view(-1)**2\n",
    "u = y_test_cmp_var\n",
    "print(\"mean err2:\", err2.mean().item(), \"mean u:\", u.mean().item())\n",
    "print(\"corr(err2, u):\", torch.corrcoef(torch.stack([err2, u]))[0,1].item())\n"
   ],
   "id": "f5f522aafbb382fc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictive MSE (centralized OLS, real data only): 0.1400873064994812\n",
      "Predictive MSE using mean of K MP samples: 0.7694464325904846\n",
      "ENCE (Non Bayesian OLS, real data only): 0.286159160128087\n",
      "ENCE (CMP): 1.9356541463905939\n",
      "mean err2: 0.7694464325904846 mean u: 0.10005893558263779\n",
      "corr(err2, u): 0.0841580182313919\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-17T13:03:49.077678Z",
     "start_time": "2025-12-17T13:03:48.964880Z"
    }
   },
   "cell_type": "code",
   "source": [
    "clients_x_train = []\n",
    "clients_y_train = []\n",
    "clients_x_test = []\n",
    "clients_y_test = []\n",
    "clients_context = []\n",
    "clients_induces = None\n",
    "\n",
    "M = 10\n",
    "\n",
    "pma = PMA(d_ctx, 5, 5, ln=True).to(device)\n",
    "pma_dict = torch.load(\"checkpoint/pma_model_federated_5.pt\")\n",
    "pma.load_state_dict(pma_dict)\n",
    "\n",
    "for m in range(M):\n",
    "    data = np.load(f\"data/client_{m}.npz\")\n",
    "    \n",
    "    X_m_train = torch.from_numpy(data[\"X_train\"]).float().to(device)\n",
    "    y_m_train = torch.from_numpy(data[\"y_train\"]).unsqueeze(-1).float().to(device)\n",
    "    X_m_test = torch.from_numpy(data[\"X_test\"]).float().to(device)\n",
    "    y_m_test = torch.from_numpy(data[\"y_test\"]).unsqueeze(-1).float().to(device)\n",
    "    context_m = torch.cat((X_m_train, y_m_train), dim=1)\n",
    "    \n",
    "    clients_x_train.append(X_m_train)\n",
    "    clients_y_train.append(y_m_train)\n",
    "    clients_x_test.append(X_m_test)\n",
    "    clients_y_test.append(y_m_test)\n",
    "    clients_context.append(context_m)\n",
    "    \n",
    "    induce_m = pma(context_m)\n",
    "    clients_induces = induce_m if m == 0 else torch.cat((clients_induces, induce_m), dim=0)\n",
    "\n",
    "W_fmp = []\n",
    "\n",
    "for k in range(K):\n",
    "    with torch.no_grad():\n",
    "        pred_client_induces = isab(clients_induces)\n",
    "    \n",
    "    X_induce = clients_induces[:, :d_x]\n",
    "    y_induce = clients_induces[:, d_x:]\n",
    "    X_pred_induce = pred_client_induces[:, :d_x]\n",
    "    y_pred_induce = pred_client_induces[:, d_x:]\n",
    "    \n",
    "    X_induce_aug = torch.cat((X_induce, X_pred_induce), dim=0)\n",
    "    y_induce_aug = torch.cat((y_induce, y_pred_induce), dim=0)\n",
    "    \n",
    "    XTX_induce = X_induce_aug.T@X_induce_aug\n",
    "    XTy_induce = X_induce_aug.T@y_induce_aug\n",
    "    W_induce = torch.linalg.solve(XTX_induce, XTy_induce)\n",
    "    \n",
    "    W_fmp.append(W_induce)\n",
    "\n",
    "with torch.no_grad():    \n",
    "    W_fmp_mean = torch.mean(torch.stack(W_fmp, dim=0), dim=0)\n",
    "    y_fmp_mean = X_test @ W_fmp_mean\n",
    "    mse_fmp_mean = torch.mean((y_fmp_mean - y_test) ** 2).item()\n",
    "    print(f\"FMP Predictive MSE using mean of K MP samples: {mse_fmp_mean}\")\n",
    "    "
   ],
   "id": "eb1dd8bb08bc5347",
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/client_5.npz'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[23], line 15\u001B[0m\n\u001B[1;32m     12\u001B[0m pma\u001B[38;5;241m.\u001B[39mload_state_dict(pma_dict)\n\u001B[1;32m     14\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(M):\n\u001B[0;32m---> 15\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43mf\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mdata/client_\u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[43mm\u001B[49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[38;5;124;43m.npz\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m     17\u001B[0m     X_m_train \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mfrom_numpy(data[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mX_train\u001B[39m\u001B[38;5;124m\"\u001B[39m])\u001B[38;5;241m.\u001B[39mfloat()\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[1;32m     18\u001B[0m     y_m_train \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mfrom_numpy(data[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124my_train\u001B[39m\u001B[38;5;124m\"\u001B[39m])\u001B[38;5;241m.\u001B[39munsqueeze(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\u001B[38;5;241m.\u001B[39mfloat()\u001B[38;5;241m.\u001B[39mto(device)\n",
      "File \u001B[0;32m/home/largeDisk/boning/miniconda3/envs/py39/lib/python3.9/site-packages/numpy/lib/npyio.py:427\u001B[0m, in \u001B[0;36mload\u001B[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001B[0m\n\u001B[1;32m    425\u001B[0m     own_fid \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[1;32m    426\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 427\u001B[0m     fid \u001B[38;5;241m=\u001B[39m stack\u001B[38;5;241m.\u001B[39menter_context(\u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mos_fspath\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfile\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mrb\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m)\n\u001B[1;32m    428\u001B[0m     own_fid \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m    430\u001B[0m \u001B[38;5;66;03m# Code to distinguish from NumPy binary files and pickles.\u001B[39;00m\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'data/client_5.npz'"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-13T19:11:29.966440Z",
     "start_time": "2025-12-13T19:11:29.577356Z"
    }
   },
   "cell_type": "code",
   "source": [
    "W_clients = []\n",
    "\n",
    "client_induces = None\n",
    "\n",
    "sum_mse = 0.0\n",
    "\n",
    "for m in range(M):\n",
    "    X_m = clients_x_train[m]\n",
    "    y_m = clients_y_train[m]\n",
    "    X_m_test = clients_x_test[m]\n",
    "    y_m_test = clients_y_test[m]\n",
    "    context_m = clients_context[m]\n",
    "\n",
    "    W_m_augs = []\n",
    "    \n",
    "    for i in range(K):\n",
    "        predictive_m = isab(context_m)\n",
    "        predictive_mx, predictive_my = predictive_m[:, :d_x], predictive_m[:, d_x:]\n",
    "        \n",
    "        X_m_aug = torch.cat((X_m, predictive_mx), dim=0)\n",
    "        y_m_aug = torch.cat((y_m, predictive_my), dim=0)\n",
    "        \n",
    "        XTX = X_m_aug.T @ X_m_aug\n",
    "        XTy = X_m_aug.T @ y_m_aug\n",
    "        w_m_aug = torch.linalg.solve(XTX, XTy)\n",
    "        \n",
    "        W_m_augs.append(w_m_aug)\n",
    "        \n",
    "    XTX_m = X_m.T @ X_m\n",
    "    XTy_m = X_m.T @ y_m\n",
    "    w_m_real = torch.linalg.solve(XTX_m, XTy_m)\n",
    "    y_m_test_real = X_m_test @ w_m_real\n",
    "    mse_m_test_real = torch.mean((y_m_test_real - y_m_test) ** 2).item()\n",
    "    print(f\"Client {m} Predictive MSE (Local OLS, real data only): {mse_m_test_real}\")\n",
    "    \n",
    "    W_m_augs_mean = torch.mean(torch.stack(W_m_augs, dim=0), dim=0)\n",
    "    y_m_test_augs_mean = X_m_test @ W_m_augs_mean\n",
    "    mse_m_test_augs_mean = torch.mean((y_m_test_augs_mean - y_m_test) ** 2).item()\n",
    "    print(f\"Client {m} Predictive MSE using mean of K MP samples: {mse_m_test_augs_mean}\")\n",
    "    \n",
    "    sum_mse += mse_m_test_augs_mean\n",
    "  \n",
    "    W_clients.append(W_m_augs)\n",
    "    \n",
    "print(sum_mse / M)\n"
   ],
   "id": "acb3df4aa0a6e56b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 0 Predictive MSE (Local OLS, real data only): 1.5319807529449463\n",
      "Client 0 Predictive MSE using mean of K MP samples: 0.7516019940376282\n",
      "Client 1 Predictive MSE (Local OLS, real data only): 0.924592137336731\n",
      "Client 1 Predictive MSE using mean of K MP samples: 0.5601908564567566\n",
      "Client 2 Predictive MSE (Local OLS, real data only): 2.896517038345337\n",
      "Client 2 Predictive MSE using mean of K MP samples: 1.1962809562683105\n",
      "Client 3 Predictive MSE (Local OLS, real data only): 2.299551486968994\n",
      "Client 3 Predictive MSE using mean of K MP samples: 1.0130255222320557\n",
      "Client 4 Predictive MSE (Local OLS, real data only): 0.6699424386024475\n",
      "Client 4 Predictive MSE using mean of K MP samples: 0.593198835849762\n",
      "Client 5 Predictive MSE (Local OLS, real data only): 0.6372154951095581\n",
      "Client 5 Predictive MSE using mean of K MP samples: 0.6953699588775635\n",
      "Client 6 Predictive MSE (Local OLS, real data only): 12.974235534667969\n",
      "Client 6 Predictive MSE using mean of K MP samples: 1.4980835914611816\n",
      "Client 7 Predictive MSE (Local OLS, real data only): 1.5201281309127808\n",
      "Client 7 Predictive MSE using mean of K MP samples: 0.7723116874694824\n",
      "Client 8 Predictive MSE (Local OLS, real data only): 0.5657268166542053\n",
      "Client 8 Predictive MSE using mean of K MP samples: 0.5642103552818298\n",
      "Client 9 Predictive MSE (Local OLS, real data only): 661.071533203125\n",
      "Client 9 Predictive MSE using mean of K MP samples: 1.7848436832427979\n",
      "0.9429117441177368\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-07T19:01:06.049449Z",
     "start_time": "2025-12-07T19:01:06.017487Z"
    }
   },
   "cell_type": "code",
   "source": [
    "Sigma_inv_list = []\n",
    "precision_sum = torch.zeros(d_x, d_x, device=device)\n",
    "\n",
    "# for m in range(M):\n",
    "#     W_m = torch.stack([w.squeeze(-1) for w in W_clients[m]], dim=0)  # (K, d)\n",
    "# \n",
    "#     var_m = W_m.var(dim=0, unbiased=True)    # (d,)\n",
    "#     eps = 1e-6\n",
    "#     Sigma_m = torch.diag(var_m + eps)        # (d, d)\n",
    "# \n",
    "#     Sigma_inv_m = torch.linalg.inv(Sigma_m)  # (d, d)\n",
    "#     Sigma_inv_list.append(Sigma_inv_m)\n",
    "# \n",
    "#     precision_sum += Sigma_inv_m             #∑_m Σ_m^{-1}\n",
    "\n",
    "for m in range(M):\n",
    "\n",
    "    W_m = torch.stack([w.view(-1) for w in W_clients[m]], dim=0)   # (K, d)\n",
    "\n",
    "\n",
    "    mean_m = W_m.mean(dim=0, keepdim=True)                         # (1, d)\n",
    "    centered = W_m - mean_m                                        # (K, d)\n",
    "\n",
    "    cov_m = centered.T @ centered / (K - 1)                    # (d, d)\n",
    "\n",
    "    Sigma_inv_m = torch.linalg.pinv(cov_m)                        # (d, d)\n",
    "    Sigma_inv_list.append(Sigma_inv_m)\n",
    "\n",
    "    precision_sum += Sigma_inv_m \n",
    "\n",
    "W_cfmp = [] \n",
    "\n",
    "for k in range(K):\n",
    "    \n",
    "    weighted_sum_k = torch.zeros(d_x, 1, device=device)  # ∑_m Σ_m^{-1} w_m^{(k)}\n",
    "\n",
    "    for m in range(M):\n",
    "        w_m_k = W_clients[m][k]   # (d, 1)\n",
    "        Sigma_inv_m = Sigma_inv_list[m]\n",
    "        weighted_sum_k += Sigma_inv_m @ w_m_k\n",
    "\n",
    "    w_cfmp_k = torch.linalg.solve(precision_sum, weighted_sum_k)   # (d, 1)\n",
    "    W_cfmp.append(w_cfmp_k)\n",
    "\n",
    "W_cfmp_mean = torch.mean(torch.stack(W_cfmp, dim=0), dim=0)\n",
    "y_cfmp_mean = X_test @ W_cfmp_mean\n",
    "mse_cfmp_mean = torch.mean((y_cfmp_mean - y_test) ** 2).item()\n",
    "print(f\"CFMP Predictive MSE using mean of K MP samples: {mse_cfmp_mean}\")\n"
   ],
   "id": "f53b1086d648ca9c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CFMP Predictive MSE using mean of K MP samples: 0.7305290699005127\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-07T19:03:20.536509Z",
     "start_time": "2025-12-07T19:03:20.524421Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def _rbf_kernel(x: torch.Tensor, y: torch.Tensor, sigmas=None):\n",
    "\n",
    "    if sigmas is None:\n",
    "        sigmas = torch.tensor([0.5, 1.0, 2.0, 5.0, 10.0], device=x.device, dtype=x.dtype)\n",
    "    elif not torch.is_tensor(sigmas):\n",
    "        sigmas = torch.tensor(sigmas, device=x.device, dtype=x.dtype)\n",
    "\n",
    "    x_norm = (x ** 2).sum(dim=1, keepdim=True)  # (n, 1)\n",
    "    y_norm = (y ** 2).sum(dim=1, keepdim=True)  # (m, 1)\n",
    "\n",
    "    dist2 = x_norm + y_norm.T - 2.0 * (x @ y.T)\n",
    "\n",
    "    sigmas = sigmas.view(-1, 1, 1)\n",
    "    gamma = 1.0 / (2.0 * sigmas ** 2)\n",
    "\n",
    "    kernel = torch.exp(-gamma * dist2)  # (num_sigmas, n, m)\n",
    "    kernel = kernel.mean(dim=0)  # (n, m)\n",
    "    return kernel\n",
    "\n",
    "\n",
    "def mmd_rbf(X: torch.Tensor, Y: torch.Tensor, sigmas=None):\n",
    "    X = X.detach()\n",
    "    Y = Y.detach()\n",
    "\n",
    "    Kxx = _rbf_kernel(X, X, sigmas=sigmas)\n",
    "    Kyy = _rbf_kernel(Y, Y, sigmas=sigmas)\n",
    "    Kxy = _rbf_kernel(X, Y, sigmas=sigmas)\n",
    "    \n",
    "    n = X.size(0)\n",
    "    m = Y.size(0)\n",
    "\n",
    "    # unbiased MMD^2    E[k(x,x')] - E[k(x,y)]*2 + E[k(y,y')]\n",
    "    sum_Kxx = (Kxx.sum() - Kxx.diag().sum()) / (n * (n - 1))\n",
    "    sum_Kyy = (Kyy.sum() - Kyy.diag().sum()) / (m * (m - 1))\n",
    "    sum_Kxy = Kxy.mean()\n",
    "\n",
    "    dis = sum_Kxx + sum_Kyy - 2.0 * sum_Kxy\n",
    "    dis = torch.clamp(dis, min=0.0) \n",
    "\n",
    "    return dis"
   ],
   "id": "f093d8afa8ae3a1f",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-07T19:03:22.909149Z",
     "start_time": "2025-12-07T19:03:22.899590Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# CMP samples: centralized martingale posterior samples w_c^{(k)}\n",
    "W_cmp = torch.stack([w.view(-1) for w in W_cmps], dim=0) # (K, d)\n",
    "\n",
    "# CFMP samples: aggregated martingale posterior samples w_cfmp^{(k)}\n",
    "W_cfmp = torch.stack([w.view(-1) for w in W_cfmp], dim=0)  # (K, d)\n",
    "\n",
    "# FMP samples: aggregated induced martingale posterior samples w_fmp^{(k)}\n",
    "W_fmp = torch.stack([w.view(-1) for w in W_fmp], dim=0)\n",
    "\n",
    "mmd2 = mmd_rbf(W_cmp, W_cfmp)\n",
    "\n",
    "print(\"MMD^2 between CMP and CFMP parameter samples:\", mmd2.item())\n",
    "\n",
    "mmd2 = mmd_rbf(W_cmp, W_fmp)\n",
    "\n",
    "print(\"MMD^2 between CMP and FMP parameter samples:\", mmd2.item())"
   ],
   "id": "208cceff695d9ea5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MMD^2 between CMP and CFMP parameter samples: 0.26233935356140137\n",
      "MMD^2 between CMP and FMP parameter samples: 7.462501525878906e-05\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-07T19:03:34.114891Z",
     "start_time": "2025-12-07T19:03:34.091575Z"
    }
   },
   "cell_type": "code",
   "source": [
    "mmd2_local_list = []\n",
    "\n",
    "for m in range(M):\n",
    "    W_local_m = torch.stack([w.view(-1) for w in W_clients[m]], dim=0).to(device)  # (K, d)\n",
    "\n",
    "    mmd2_m = mmd_rbf(W_cmp, W_local_m)\n",
    "    mmd2_local_list.append(mmd2_m.item())\n",
    "\n",
    "    print(f\"Client {m}: MMD^2 between CMP and local MP = {mmd2_m.item():.6f}\")\n",
    "    \n",
    "    X_m_test = clients_x_test[m]\n",
    "    y_m_test = clients_y_test[m]\n",
    "    \n",
    "    W_cfmp_mean = torch.mean(W_cfmp, dim=0)\n",
    "    y_cfmp_mean = X_m_test @ W_cfmp_mean\n",
    "    mse_m_test_cfmp_mean = torch.mean((y_cfmp_mean - y_m_test) ** 2).item()\n",
    "    print(f\"Predictive MSE using mean of K CFMP samples: {mse_m_test_cfmp_mean}\")\n",
    "    \n",
    "    W_fmp_mean = torch.mean(W_fmp, dim=0)\n",
    "    y_fmp_mean = X_m_test @ W_fmp_mean\n",
    "    mse_m_test_fmp_mean = torch.mean((y_fmp_mean - y_m_test) ** 2).item()\n",
    "    print(f\"Predictive MSE using mean of K FMP samples: {mse_m_test_fmp_mean}\")\n",
    "    \n",
    "print(\"Average MMD^2 between CMP and local MPs:\", sum(mmd2_local_list) / len(mmd2_local_list))"
   ],
   "id": "340f3b446f9efe4a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 0: MMD^2 between CMP and local MP = 0.242160\n",
      "Predictive MSE using mean of K CFMP samples: 1.7601854801177979\n",
      "Predictive MSE using mean of K FMP samples: 1.458784580230713\n",
      "Client 1: MMD^2 between CMP and local MP = 0.176329\n",
      "Predictive MSE using mean of K CFMP samples: 1.7120976448059082\n",
      "Predictive MSE using mean of K FMP samples: 1.461951494216919\n",
      "Client 2: MMD^2 between CMP and local MP = 0.417859\n",
      "Predictive MSE using mean of K CFMP samples: 1.4670337438583374\n",
      "Predictive MSE using mean of K FMP samples: 1.2806888818740845\n",
      "Client 3: MMD^2 between CMP and local MP = 0.293935\n",
      "Predictive MSE using mean of K CFMP samples: 1.5326499938964844\n",
      "Predictive MSE using mean of K FMP samples: 1.2608627080917358\n",
      "Client 4: MMD^2 between CMP and local MP = 0.241214\n",
      "Predictive MSE using mean of K CFMP samples: 1.613072395324707\n",
      "Predictive MSE using mean of K FMP samples: 1.322301983833313\n",
      "Client 5: MMD^2 between CMP and local MP = 0.225421\n",
      "Predictive MSE using mean of K CFMP samples: 1.5717130899429321\n",
      "Predictive MSE using mean of K FMP samples: 1.2604032754898071\n",
      "Client 6: MMD^2 between CMP and local MP = 0.534716\n",
      "Predictive MSE using mean of K CFMP samples: 1.7970054149627686\n",
      "Predictive MSE using mean of K FMP samples: 1.596266746520996\n",
      "Client 7: MMD^2 between CMP and local MP = 0.238975\n",
      "Predictive MSE using mean of K CFMP samples: 1.7210807800292969\n",
      "Predictive MSE using mean of K FMP samples: 1.450098991394043\n",
      "Client 8: MMD^2 between CMP and local MP = 0.171955\n",
      "Predictive MSE using mean of K CFMP samples: 1.5773084163665771\n",
      "Predictive MSE using mean of K FMP samples: 1.3167624473571777\n",
      "Client 9: MMD^2 between CMP and local MP = 0.573841\n",
      "Predictive MSE using mean of K CFMP samples: 1.5472899675369263\n",
      "Predictive MSE using mean of K FMP samples: 1.334617257118225\n",
      "Average MMD^2 between CMP and local MPs: 0.31164050102233887\n"
     ]
    }
   ],
   "execution_count": 14
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
